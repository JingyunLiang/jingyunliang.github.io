<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jingyun Liang</title>

  <meta name="author" content="Jingyun Liang">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jingyun Liang</name>
              </p>
              <p>I am currently a PhD Student at <a href="https://vision.ee.ethz.ch/">Computer Vision Lab</a>, <a href="https://ethz.ch/en.html">ETH ZÃ¼rich</a>, Switzerland. I am co-supervised by Prof. <a href="https://scholar.google.com/citations?user=TwMib_QAAAAJ&hl=en">Luc Van Gool</a> and Prof. <a href="http://people.ee.ethz.ch/~timofter/">Radu Timofte</a>. I also work closely with Dr. <a href="https://cszn.github.io/">Kai Zhang</a>. I mainly focus on low-level vision research, especially on image and video restoration, such as super-resolution, deblurring and denoising.
              </p>
              <p style="text-align:center">
                <a href="mailto:jingyunliang12@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=3-Hz9BgAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/jingyunliang/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile_large.jpg"><img style="width:80%;max-width:80%" alt="profile photo" src="images/profile.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <ul>
              <li>2022-01-28: Our new paper <a href="https://github.com/JingyunLiang/VRT">VRT</a> is online.</li>
              <li>2021-10-20: <a href="https://github.com/JingyunLiang/SwinIR">SwinIR</a> is awarded the best paper prize in ICCV-AIM2021.</li>
              <li>2021-08-01: Three papers (<a href="https://github.com/JingyunLiang/HCFlow">HCFlow</a>, <a href="https://github.com/JingyunLiang/MANet">MANet</a> and <a href="https://github.com/cszn/BSRGAN">BSRGAN</a>) accepted by ICCV2021.</li>
              <li>2021-03-29: One paper (<a href="https://github.com/JingyunLiang/FKP">FKP</a>) accepted by CVPR2021.</li>

            </ul>
          </td>
          </td>
        </tr>
      </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>






    <tr onmouseout="refnerf_stop()" onmouseover="refnerf_start()" bgcolor="#ffffd0">
      <td style="padding:0px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='refnerf_image'><video  width=100% height=60% muted autoplay loop>
          <source src="images/VRT.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/VRT.jpeg' width="160" height="90">
        </div>
        <script type="text/javascript">
          function refnerf_start() {
            document.getElementById('refnerf_image').style.opacity = "1";
          }

          function refnerf_stop() {
            document.getElementById('refnerf_image').style.opacity = "0";
          }
          refnerf_stop()
        </script>
      </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://github.com/JingyunLiang/VRT">
            <papertitle>VRT: A Video Restoration Transformer</papertitle>
          </a>
          <br>
          <strong>Jingyun Liang</strong>, Jiezhang Cao, Yuchen Fan, Kai Zhang, Rakesh Ranjan, Yawei Li, Radu Timofte and Luc Van Gool
          <br>
    <em>arxiv</em>, 2022
          <br>
          <a href="https://arxiv.org/pdf/2201.12288.pdf">arXiv</a> /
          <a href="https://github.com/JingyunLiang/VRT">code</a> /
          <a href="data/default.bib">bibtex</a>
          <p></p>
          <p>A transformer-based model that jointly extracts, aligns, and fuses frame features at multiple scales; state-of-the-art performance in video SR/ deblurring/ video denoising.</p>
        </td>
      </tr>

    <tr onmouseout="refnerf_stop()" onmouseover="refnerf_start()">
      <td style="padding:0px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='refnerf_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/no.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/MEFNet.jpg' width="160">
        </div>
        <script type="text/javascript">
          function refnerf_start() {
            document.getElementById('refnerf_image').style.opacity = "1";
          }

          function refnerf_stop() {
            document.getElementById('refnerf_image').style.opacity = "0";
          }
          refnerf_stop()
        </script>
      </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/pdf/2112.00167.pdf">
            <papertitle>MEFNet: Multi-Scale Event Fusion Network for Motion Deblurring</papertitle>
          </a>
          <br>
                Lei Sun, Christos Sakaridis, <strong>Jingyun Liang</strong>, Qi Jiang, Kailun Yang, Peng Sun, Yaozu Ye, Kaiwei Wang and Luc Van Gool
          <br>
    <em>arxiv</em>, 2021
          <br>
          <a href="https://arxiv.org/pdf/2112.00167.pdf">arXiv</a> /
          code (coming soon)</a> /
          dataset (coming soon)</a> /
          <a href="data/default.bib">bibtex</a>
          <p></p>
          <p>An unfolded end-to-end event camera-based motion deblurring method; a High-Quality Blur (HQBlur) dataset for event camera-based deblurring.</p>
        </td>
      </tr>

    <tr onmouseout="refnerf_stop()" onmouseover="refnerf_start()" bgcolor="#ffffd0">
      <td style="padding:0px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='refnerf_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/no.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/SwinIR.jpeg' width="160" height="100">
        </div>
        <script type="text/javascript">
          function refnerf_start() {
            document.getElementById('refnerf_image').style.opacity = "1";
          }

          function refnerf_stop() {
            document.getElementById('refnerf_image').style.opacity = "0";
          }
          refnerf_stop()
        </script>
      </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://github.com/JingyunLiang/SwinIR">
            <papertitle>SwinIR: Image Restoration Using Swin Transformer</papertitle>
          </a>
          <br>
          <strong>Jingyun Liang</strong>, Jiezhang Cao, Guolei Sun, Kai Zhang, Luc Van Gool and Radu Timofte
          <br>
    <em>IEEE International Conference on Computer Vision Workshops (<strong>ICCVW</strong>)</em>, 2021
          <br>
          <a href="https://arxiv.org/pdf/2108.10257.pdf">arXiv</a> /
          <a href="https://github.com/JingyunLiang/SwinIR">code</a> /
          <a href="https://colab.research.google.com/gist/JingyunLiang/a5e3e54bc9ef8d7bf594f6fee8208533/swinir-demo-on-real-world-image-sr.ipynb">online demo</a> /
          <a href="data/default.bib">bibtex</a>
          <p></p>
          <p>A transformer-based image restoration that allows content-based interactions and long-range dependency modelling; state-of-the-art performance on image SR, denoising and JPEG compression artifact reduction.</p>
        </td>
      </tr>

    <tr onmouseout="refnerf_stop()" onmouseover="refnerf_start()">
      <td style="padding:0px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='refnerf_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/no.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/BSRGAN.jpg' width="160" height="110">
        </div>
        <script type="text/javascript">
          function refnerf_start() {
            document.getElementById('refnerf_image').style.opacity = "1";
          }

          function refnerf_stop() {
            document.getElementById('refnerf_image').style.opacity = "0";
          }
          refnerf_stop()
        </script>
      </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://github.com/cszn/BSRGAN">
            <papertitle>Designing a Practical Degradation Model for Deep Blind Image Super-Resolution</papertitle>
          </a>
          <br>
          Kai Zhang, <strong>Jingyun Liang</strong>, Luc Van Gool and Radu Timofte
          <br>
          <em>IEEE International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2021
          <br>
          <a href="https://arxiv.org/pdf/2103.14006.pdf">arXiv</a> /
          <a href="https://github.com/cszn/BSRGAN">code</a> /
          <a href="https://colab.research.google.com/gist/JingyunLiang/a5e3e54bc9ef8d7bf594f6fee8208533/swinir-demo-on-real-world-image-sr.ipynb">online demo</a> /
          <a href="data/default.bib">bibtex</a>
          <p></p>
          <p>The first practical real-world degradation model for training real-world image SR models; impressive results on real-world images.</p>
        </td>
      </tr>

    <tr onmouseout="refnerf_stop()" onmouseover="refnerf_start()">
      <td style="padding:0px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='refnerf_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/no.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/HCFlow.jpg' width="160" height="140">
        </div>
        <script type="text/javascript">
          function refnerf_start() {
            document.getElementById('refnerf_image').style.opacity = "1";
          }

          function refnerf_stop() {
            document.getElementById('refnerf_image').style.opacity = "0";
          }
          refnerf_stop()
        </script>
      </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://github.com/JingyunLiang/HCFlow">
            <papertitle>Hierarchical Conditional Flow: A Unified Framework for Image Super-Resolution and Image Rescaling</papertitle>
          </a>
          <br>
          <strong>Jingyun Liang</strong>, Andreas Lugmayr, Kai Zhang, Martin Danelljan, Luc Van Gool and Radu Timofte
          <br>
    <em>IEEE International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2021
          <br>
          <a href="https://arxiv.org/pdf/2108.05301.pdf">arXiv</a> /
          <a href="https://github.com/JingyunLiang/HCFlow">code</a> /
          <a href="https://colab.research.google.com/gist/JingyunLiang/cdb3fef89ebd174eaa43794accb6f59d/hcflow-demo-on-x8-face-image-sr.ipynb">online demo</a> /
          <a href="data/default.bib">bibtex</a>
          <p></p>
          <p>It learns a bijective mapping between HR and LR image pairs by modelling low and high-frequency components; a unified framework for image SR and image rescaling.</p>
        </td>
      </tr>

    <tr onmouseout="refnerf_stop()" onmouseover="refnerf_start()">
      <td style="padding:0px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='refnerf_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/no.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/MANet.jpg' width="160">
        </div>
        <script type="text/javascript">
          function refnerf_start() {
            document.getElementById('refnerf_image').style.opacity = "1";
          }

          function refnerf_stop() {
            document.getElementById('refnerf_image').style.opacity = "0";
          }
          refnerf_stop()
        </script>
      </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://github.com/JingyunLiang/MANet">
            <papertitle>Mutual Affine Network for Spatially Variant Kernel Estimation in Blind Image Super-Resolution</papertitle>
          </a>
          <br>
          <strong>Jingyun Liang</strong>, Guolei Sun, Kai Zhang, Luc Van Gool and Radu Timofte
          <br>
          <em>IEEE International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2021
          <br>
          <a href="https://arxiv.org/pdf/2108.05302.pdf">arXiv</a> /
          <a href="https://github.com/JingyunLiang/MANet">code</a> /
          <a href="https://colab.research.google.com/gist/JingyunLiang/4ed2524d6e08343710ee408a4d997e1c/manet-demo-on-spatially-variant-kernel-estimation.ipynb">online demo</a> /
          <a href="data/default.bib">bibtex</a>
          <p></p>
          <p>A kernel estimation network with mutual affine convolution for spatially variant kernels; state-of-the-art blind SR performance.</p>
        </td>
      </tr>

    <tr onmouseout="refnerf_stop()" onmouseover="refnerf_start()">
      <td style="padding:0px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='refnerf_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/no.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/FKP.jpg' width="160" height="110">
        </div>
        <script type="text/javascript">
          function refnerf_start() {
            document.getElementById('refnerf_image').style.opacity = "1";
          }

          function refnerf_stop() {
            document.getElementById('refnerf_image').style.opacity = "0";
          }
          refnerf_stop()
        </script>
      </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://github.com/JingyunLiang/FKP">
            <papertitle>Flow-based Kernel Prior with Application to Blind Super-Resolution</papertitle>
          </a>
          <br>
          <strong>Jingyun Liang</strong>, Kai Zhang, Shuhang Gu, Luc Van Gool, Radu Timofte
          <br>
          <em>IEEE International Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2021
          <br>
          <a href="https://arxiv.org/pdf/2103.15977.pdf">arXiv</a> /
          <a href="https://github.com/JingyunLiang/FKP">code</a> /
          <a href="data/default.bib">bibtex</a>
          <p></p>
          <p>A normalizing flow-based kernel prior for kernel modeling; state-of-the-art performance in unsupervised blind SR.</p>
        </td>
      </tr>

        </tbody></table>


</tbody></table>




        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <p style="text-align:center;font-size:small;" width=50% height=50%>
          <div id="sfcz4tfhfy9rksbe6szt746puqcpf8xayls"></div><script type="text/javascript" src="https://counter2.stat.ovh/private/counter.js?c=z4tfhfy9rksbe6szt746puqcpf8xayls&down=async" async></script><br><noscript><a href="https://www.freecounterstat.com" title="page counter"><img src="https://counter2.stat.ovh/private/freecounterstat.php?c=z4tfhfy9rksbe6szt746puqcpf8xayls" border="0" title="page counter" alt="page counter"></a></noscript></p>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Template from <a href="http://jonbarron.info">Jon Barron .
                <br>
              </p>
            </td>
          </tr>

        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
